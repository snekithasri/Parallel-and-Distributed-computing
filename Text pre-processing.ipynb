{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f194881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "adc15284",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b55ce6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Number of text samples 7532\n",
      "done in 0.623s.\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading dataset...\")\n",
    "t0 = time.time()\n",
    "data = fetch_20newsgroups(subset=\"test\")\n",
    "#shuffle=True, random_state=1,remove=('headers', 'footers', 'quotes')\n",
    "print(\"Number of text samples {}\".format(len(data.data)))\n",
    "print(\"done in %0.3fs.\" % (time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ebef3172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'From: v064mb9k@ubvmsd.cc.buffalo.edu (NEIL B. GANDLER)\\nSubject: Need info on 88-89 Bonneville\\nOrganization: University at Buffalo\\nLines: 10\\nNews-Software: VAX/VMS VNEWS 1.41\\nNntp-Posting-Host: ubvmsd.cc.buffalo.edu\\n\\n\\n I am a little confused on all of the models of the 88-89 bonnevilles.\\nI have heard of the LE SE LSE SSE SSEI. Could someone tell me the\\ndifferences are far as features or performance. I am also curious to\\nknow what the book value is for prefereably the 89 model. And how much\\nless than book value can you usually get them for. In other words how\\nmuch are they in demand this time of year. I have heard that the mid-spring\\nearly summer is the best time to buy.\\n\\n\\t\\t\\tNeil Gandler\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40bf52ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: v064mb9k@ubvmsd.cc.buffalo.edu (NEIL B. ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: Rick Miller &lt;rick@ee.uwm.edu&gt;\\nSubject: ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: mathew &lt;mathew@mantis.co.uk&gt;\\nSubject: R...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: bakken@cs.arizona.edu (Dave Bakken)\\nSub...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: livesey@solntze.wpd.sgi.com (Jon Livesey...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  From: v064mb9k@ubvmsd.cc.buffalo.edu (NEIL B. ...       7\n",
       "1  From: Rick Miller <rick@ee.uwm.edu>\\nSubject: ...       5\n",
       "2  From: mathew <mathew@mantis.co.uk>\\nSubject: R...       0\n",
       "3  From: bakken@cs.arizona.edu (Dave Bakken)\\nSub...      17\n",
       "4  From: livesey@solntze.wpd.sgi.com (Jon Livesey...      19"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df = df.assign(text=data[\"data\"]).assign(target=data[\"target\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be089a8c",
   "metadata": {},
   "source": [
    "### Cleaning text eg:Removing email address,newline characters,punctuation,etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e2c34cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: (NEIL B. GANDLER)\n",
      "Subject: Need info on 88-89 Bonneville\n",
      "Organization: University at Buffalo\n",
      "Lines: 10\n",
      "News-Software: VAX/VMS VNEWS 1.41\n",
      "Nntp-Posting-Host: ubvmsd.cc.buffalo.edu\n",
      "\n",
      "\n",
      " I am a little confused on all of the models of the 88-89 bonnevilles.\n",
      "I have heard of the LE SE LSE SSE SSEI. Could someone tell me the\n",
      "differences are far as features or performance. I am also curious to\n",
      "know what the book value is for prefereably the 89 model. And how much\n",
      "less than book value can you usually get them for. In other words how\n",
      "much are they in demand this time of year. I have heard that the mid-spring\n",
      "early summer is the best time to buy.\n",
      "\n",
      "\t\t\tNeil Gandler\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re #re can be used to check if a string contains the specified search pattern.\n",
    "def remove_emails(text):\n",
    "    regex =  r'\\S*@\\S*\\s?'\n",
    "    return re.sub(regex, '', text)\n",
    "test_text=remove_emails(data.data[0])\n",
    "print(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9af9856c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: (NEIL B. GANDLER) Subject: Need info on 88-89 Bonneville Organization: University at Buffalo Lines: 10 News-Software: VAX/VMS VNEWS 1.41 Nntp-Posting-Host: ubvmsd.cc.buffalo.edu I am a little confused on all of the models of the 88-89 bonnevilles. I have heard of the LE SE LSE SSE SSEI. Could someone tell me the differences are far as features or performance. I am also curious to know what the book value is for prefereably the 89 model. And how much less than book value can you usually get them for. In other words how much are they in demand this time of year. I have heard that the mid-spring early summer is the best time to buy. Neil Gandler \n"
     ]
    }
   ],
   "source": [
    "def remove_newlinechars(text):\n",
    "    regex = r'\\s+'\n",
    "    return re.sub(regex, ' ', text)\n",
    "test_text = remove_newlinechars(test_text)\n",
    "print(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c9853633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['From', 'NEIL', 'GANDLER', 'Subject', 'Need', 'info', 'on', 'Bonneville', 'Organization', 'University', 'at', 'Buffalo', 'Lines', '10', 'VNEWS', 'I', 'am', 'a', 'little', 'confused', 'on', 'all', 'of', 'the', 'models', 'of', 'the', 'bonnevilles', 'I', 'have', 'heard', 'of', 'the', 'LE', 'SE', 'LSE', 'SSE', 'SSEI', 'Could', 'someone', 'tell', 'me', 'the', 'differences', 'are', 'far', 'as', 'features', 'or', 'performance', 'I', 'am', 'also', 'curious', 'to', 'know', 'what', 'the', 'book', 'value', 'is', 'for', 'prefereably', 'the', '89', 'model', 'And', 'how', 'much', 'less', 'than', 'book', 'value', 'can', 'you', 'usually', 'get', 'them', 'for', 'In', 'other', 'words', 'how', 'much', 'are', 'they', 'in', 'demand', 'this', 'time', 'of', 'year', 'I', 'have', 'heard', 'that', 'the', 'early', 'summer', 'is', 'the', 'best', 'time', 'to', 'buy', 'Neil', 'Gandler']\n"
     ]
    }
   ],
   "source": [
    "import nltk #text processing library\n",
    "def tokenize(text):\n",
    "    tokens = nltk.word_tokenize(text)    \n",
    "    return list(filter(lambda word: word.isalnum(), tokens))\n",
    "test_text = tokenize(test_text)\n",
    "print(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f19c75c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert text to lowercase\n",
    "test_text = [e.lower() for e in test_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0ab2bf83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neil', 'gandler', 'need', 'info', 'bonneville', 'organization', 'university', 'buffalo', 'lines', '10', 'vnews', 'little', 'confused', 'models', 'bonnevilles', 'heard', 'le', 'se', 'lse', 'sse', 'ssei', 'could', 'someone', 'tell', 'differences', 'far', 'features', 'performance', 'also', 'curious', 'know', 'book', 'value', 'prefereably', '89', 'model', 'much', 'less', 'book', 'value', 'usually', 'get', 'words', 'much', 'demand', 'time', 'year', 'heard', 'early', 'summer', 'best', 'time', 'buy', 'neil', 'gandler']\n"
     ]
    }
   ],
   "source": [
    "#Remove stopwords - the words in any language which does not add much meaning to a sentence\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words(\"english\")\n",
    "# eg:i,a,an,from,etc..\n",
    "stop_words.extend([\"from\",\"subject\",\"summary\",\"keywords\", \"article\"])\n",
    "\n",
    "def remove_stopwords(words):\n",
    "    filtered = filter(lambda word: word not in stop_words, words)\n",
    "    return list(filtered)\n",
    "\n",
    "test_text = remove_stopwords(test_text)\n",
    "print(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a0b0a193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neil', 'gandler', 'need', 'info', 'bonneville', 'organization', 'university', 'buffalo', 'line', '10', 'vnew', 'little', 'confused', 'model', 'bonneville', 'hear', 'le', 'se', 'lse', 'sse', 'ssei', 'could', 'someone', 'tell', 'difference', 'far', 'feature', 'performance', 'also', 'curious', 'know', 'book', 'value', 'prefereably', '89', 'model', 'much', 'less', 'book', 'value', 'usually', 'get', 'word', 'much', 'demand', 'time', 'year', 'hear', 'early', 'summer', 'good', 'time', 'buy', 'neil', 'gandler']\n"
     ]
    }
   ],
   "source": [
    "#Lemmatization -uses the context in which the word is being used eg:good=>better\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\") #English pipeline optimized for CPU\n",
    "def lemmatize(text, nlp=nlp):\n",
    "    doc = nlp(\" \".join(text))\n",
    "    lemmatized = [token.lemma_ for token in doc]\n",
    "    return lemmatized\n",
    "test_text = lemmatize(test_text,nlp)\n",
    "print(test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8a11a8",
   "metadata": {},
   "source": [
    "### Processing text without parallelization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "47678a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "def clean_text(df):\n",
    "    df[\"cleaned_text\"] = df.text.map(lambda text:text.lower()).map(remove_emails).map(remove_newlinechars).map(remove_stopwords).map(lemmatize)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "44c2ddd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to process without Dask 2297.4252076148987\n"
     ]
    }
   ],
   "source": [
    "df = clean_text(df)\n",
    "t1 = time.time()\n",
    "print(\"Time to process without Dask {}\".format(t1-t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7162f4",
   "metadata": {},
   "source": [
    "### Processing text with parallelization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fc074b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as ddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "410b721a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_dataframe = ddf.from_pandas(df, npartitions=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0c1d86ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "697b26a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-18ffa1218d39>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"cleaned_text\"] = df.text.map(lambda text:text.lower()).map(remove_emails).map(remove_newlinechars).map(remove_stopwords).map(lemmatize)\n"
     ]
    }
   ],
   "source": [
    "result = dask_dataframe.map_partitions(clean_text, meta=df)\n",
    "df = result.compute()\n",
    "t1 =time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f9552106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to process with Dask 1427.526255607605\n"
     ]
    }
   ],
   "source": [
    "print(\"Time to process with Dask {}\".format(t1-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b2f6e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86a18945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process 0 has data: [0. 1. 2. 3.]\n"
     ]
    }
   ],
   "source": [
    "from mpi4py import MPI\n",
    "import numpy as np\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "if rank == 0:\n",
    "    data = np.arange(4.0)\n",
    "else:\n",
    "    data = np.zeros(4)\n",
    "\n",
    "comm.Bcast(data, root=0)\n",
    "\n",
    "print('Process {} has data:'.format(rank), data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cba5df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will be scattering: [1]\n",
      "Rank 0 has data: 2\n",
      "Master: [2]\n"
     ]
    }
   ],
   "source": [
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "size = comm.Get_size()\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "if rank == 0:\n",
    "   data = [(x+10)**x for x in range(size)]\n",
    "   print ('We will be scattering:',data)\n",
    "else:\n",
    "   data = None\n",
    "   \n",
    "data = comm.scatter(data, root=0)\n",
    "data += 1\n",
    "\n",
    "print ('Rank',rank,'has data:',data)\n",
    "\n",
    "newData = comm.gather(data,root=0)\n",
    "\n",
    "if rank == 0:\n",
    "   print ('Master:',newData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "848e4ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpi4py import MPI\n",
    "import numpy as np\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "size = comm.Get_size()\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "if rank == 0:\n",
    "    data = np.arange(4.)\n",
    "    for i in range(1, size):\n",
    "        req = comm.Isend(data, dest=i, tag=i)\n",
    "        req.Wait()\n",
    "        print('Process {} sent data:'.format(rank), data)\n",
    "\n",
    "else:\n",
    "    data = np.zeros(4)\n",
    "    req = comm.Irecv(data, source=0, tag=rank)\n",
    "    req.wait()\n",
    "    print('Process {} received data:'.format(rank), data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8a9580",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
